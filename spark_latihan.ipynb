{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WxhGgCxHXuHL",
        "lxOOFVeNX1jC",
        "G2dcm8nrX7ta",
        "pUNGGrcpYBte",
        "cgCSerZAYL4v"
      ],
      "authorship_tag": "ABX9TyPdI/D8l/EhL2C7PMIgxgCB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariesabdillah/homework_spark/blob/main/spark_latihan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Google Drive"
      ],
      "metadata": {
        "id": "WxhGgCxHXuHL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMC-QPBwdGGs",
        "outputId": "1c5b994a-1870-4312-db0d-5237e9ce0f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reqruiment"
      ],
      "metadata": {
        "id": "lxOOFVeNX1jC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "#unzip the spark file to the current folder\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "#set your spark folder to your system path environment\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "\n",
        "#install findspark using pip\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_sE-DlUdXV5",
        "outputId": "a6d5d755-0210-49bd-d153-b5d9e282e797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=73ac767e6f45b517d368d1c39ff5d5af0a833ad01c481959127420ee6627025e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set your spark folder to your system path environment\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "oe29RYSvd6tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## make Spark session"
      ],
      "metadata": {
        "id": "G2dcm8nrX7ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "j8x1VVvKeDYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data from google drive"
      ],
      "metadata": {
        "id": "pUNGGrcpYBte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\")\\\n",
        "    .csv(\"/content/gdrive/MyDrive/fhv_tripdata_2019-01.csv.gz\")\n",
        "print(\"Here is our inferred schema:\")\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1ULKiUDSy1N",
        "outputId": "32949044-e54d-474e-dae0-1f590e538d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is our inferred schema:\n",
            "root\n",
            " |-- dispatching_base_num: string (nullable = true)\n",
            " |-- pickup_datetime: string (nullable = true)\n",
            " |-- dropOff_datetime: string (nullable = true)\n",
            " |-- PUlocationID: integer (nullable = true)\n",
            " |-- DOlocationID: integer (nullable = true)\n",
            " |-- SR_Flag: integer (nullable = true)\n",
            " |-- Affiliated_base_number: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdgV2qlTUJM0",
        "outputId": "9663b2a3-b009-4a32-863c-e3eac03c0e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
            "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
            "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
            "|              B00001|2019-01-01 00:30:00|2019-01-01 02:51:55|        null|        null|   null|                B00001|\n",
            "|              B00001|2019-01-01 00:45:00|2019-01-01 00:54:49|        null|        null|   null|                B00001|\n",
            "|              B00001|2019-01-01 00:15:00|2019-01-01 00:54:52|        null|        null|   null|                B00001|\n",
            "|              B00008|2019-01-01 00:19:00|2019-01-01 00:39:00|        null|        null|   null|                B00008|\n",
            "|              B00008|2019-01-01 00:27:00|2019-01-01 00:37:00|        null|        null|   null|                B00008|\n",
            "|              B00008|2019-01-01 00:48:00|2019-01-01 01:02:00|        null|        null|   null|                B00008|\n",
            "|              B00008|2019-01-01 00:50:00|2019-01-01 00:59:00|        null|        null|   null|                B00008|\n",
            "|              B00008|2019-01-01 00:51:00|2019-01-01 00:56:00|        null|        null|   null|                B00008|\n",
            "|              B00009|2019-01-01 00:44:00|2019-01-01 00:58:00|        null|        null|   null|                B00009|\n",
            "|              B00009|2019-01-01 00:19:00|2019-01-01 00:36:00|        null|        null|   null|                B00009|\n",
            "|              B00009|2019-01-01 00:36:00|2019-01-01 00:49:00|        null|        null|   null|                B00009|\n",
            "|              B00009|2019-01-01 00:26:00|2019-01-01 00:32:00|        null|        null|   null|                B00009|\n",
            "|              B00009|2019-01-01 00:26:00|2019-01-01 00:36:00|        null|        null|   null|                B00009|\n",
            "|              B00009|2019-01-01 00:58:00|2019-01-01 01:05:00|        null|        null|   null|                B00009|\n",
            "|              B00013|2019-01-01 00:02:29|2019-01-02 00:25:30|        null|        null|   null|                B00013|\n",
            "|              B00013|2019-01-01 00:01:33|2019-01-02 00:18:16|        null|        null|   null|                B00013|\n",
            "|              B00037|2019-01-01 00:02:43|2019-01-01 00:10:14|        null|         265|   null|                B00037|\n",
            "|              B00037|2019-01-01 00:26:02|2019-01-01 00:37:00|        null|         265|   null|                B00037|\n",
            "|              B00037|2019-01-01 00:11:16|2019-01-01 00:25:41|        null|         265|   null|                B00037|\n",
            "|              B00037|2019-01-01 00:33:45|2019-01-01 00:45:28|        null|         265|   null|                B00037|\n",
            "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"tripData\")"
      ],
      "metadata": {
        "id": "V-Ho5fRUTUCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform data pickup_datetime mulai tanggal 1-10 januari dan PUlocationID dan DOlocationID not null"
      ],
      "metadata": {
        "id": "cgCSerZAYL4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sqlTripData = spark.sql(\"SELECT PUlocationID, DOlocationID, pickup_datetime, dropoff_datetime \\\n",
        "FROM tripData WHERE PULocationID IS NOT NULL and DOLocationID is NOT NULL AND pickup_datetime >= '2019-01-01' \\\n",
        "AND pickup_datetime <='2019-01-10' GROUP BY pickup_datetime, DOlocationID, PUlocationID, dropoff_datetime \\\n",
        "ORDER BY pickup_datetime\")"
      ],
      "metadata": {
        "id": "J6PtJ0F9TW0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqlTripData.show()"
      ],
      "metadata": {
        "id": "Aj-nbEg9TlW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06162d57-2bf6-477f-8f3c-09fcf7358f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+-------------------+-------------------+\n",
            "|PUlocationID|DOlocationID|    pickup_datetime|   dropoff_datetime|\n",
            "+------------+------------+-------------------+-------------------+\n",
            "|         231|         234|2019-01-01 00:00:01|2019-01-01 00:29:55|\n",
            "|         229|         188|2019-01-01 00:00:01|2019-01-01 00:32:57|\n",
            "|          81|         250|2019-01-01 00:00:01|2019-01-01 00:13:55|\n",
            "|          28|         131|2019-01-01 00:00:01|2019-01-01 00:15:42|\n",
            "|         160|          36|2019-01-01 00:00:01|2019-01-01 00:10:22|\n",
            "|          69|          60|2019-01-01 00:00:02|2019-01-01 00:12:03|\n",
            "|         216|         216|2019-01-01 00:00:02|2019-01-01 00:04:54|\n",
            "|          71|          72|2019-01-01 00:00:02|2019-01-01 00:09:53|\n",
            "|          77|         188|2019-01-01 00:00:02|2019-01-01 00:24:12|\n",
            "|         137|         114|2019-01-01 00:00:02|2019-01-01 00:11:30|\n",
            "|          61|          62|2019-01-01 00:00:02|2019-01-01 00:08:10|\n",
            "|          86|         122|2019-01-01 00:00:02|2019-01-01 00:37:50|\n",
            "|         130|         216|2019-01-01 00:00:03|2019-01-01 00:09:06|\n",
            "|         169|          60|2019-01-01 00:00:03|2019-01-01 00:17:07|\n",
            "|          72|         188|2019-01-01 00:00:03|2019-01-01 00:08:44|\n",
            "|          48|         198|2019-01-01 00:00:03|2019-01-01 00:33:01|\n",
            "|         254|          74|2019-01-01 00:00:04|2019-01-01 00:17:52|\n",
            "|           4|         141|2019-01-01 00:00:04|2019-01-01 00:10:51|\n",
            "|         256|         225|2019-01-01 00:00:04|2019-01-01 00:26:43|\n",
            "|          36|          35|2019-01-01 00:00:04|2019-01-01 00:15:09|\n",
            "+------------+------------+-------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write data parquet"
      ],
      "metadata": {
        "id": "j_hKMKFkYnR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sqlTripData.write.parquet(\"TripData_parquet.parquet\")\n"
      ],
      "metadata": {
        "id": "BZVtPld2XLtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write data json"
      ],
      "metadata": {
        "id": "nKH4EqjGYwKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sqlTripData.write.json(\"TripData_json.json\")"
      ],
      "metadata": {
        "id": "I6uo39rYXc5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}